@article{Parkin:2014,
    abstract = {BACKGROUND: Brassica oleracea is a valuable vegetable species that has contributed to human health and nutrition for hundreds of years and comprises multiple distinct cultivar groups with diverse morphological and phytochemical attributes. In addition to this phenotypic wealth, B. oleracea offers unique insights into polyploid evolution, as it results from multiple ancestral polyploidy events and a final Brassiceae-specific triplication event. Further, B. oleracea represents one of the diploid genomes that formed the economically important allopolyploid oilseed, Brassica napus. A deeper understanding of B. oleracea genome architecture provides a foundation for crop improvement strategies throughout the Brassica genus.$\backslash$n$\backslash$nRESULTS: We generate an assembly representing 75{\%} of the predicted B. oleracea genome using a hybrid Illumina/Roche 454 approach. Two dense genetic maps are generated to anchor almost 92{\%} of the assembled scaffolds to nine pseudo-chromosomes. Over 50,000 genes are annotated and 40{\%} of the genome predicted to be repetitive, thus contributing to the increased genome size of B. oleracea compared to its close relative B. rapa. A snapshot of both the leaf transcriptome and methylome allows comparisons to be made across the triplicated sub-genomes, which resulted from the most recent Brassiceae-specific polyploidy event.$\backslash$n$\backslash$nCONCLUSIONS: Differential expression of the triplicated syntelogs and cytosine methylation levels across the sub-genomes suggest residual marks of the genome dominance that led to the current genome architecture. Although cytosine methylation does not correlate with individual gene dominance, the independent methylation patterns of triplicated copies suggest epigenetic mechanisms play a role in the functional diversification of duplicate genes.},
    author = {Parkin, Isobel A.P. and Koh, Chushin and Tang, Haibao and Robinson, Stephen J. and Kagale, Sateesh and Clarke, Wayne E. and Town, Chris D. and Nixon, John and Krishnakumar, Vivek and Bidwell, Shelby L. and Denoeud, France and Belcram, Harry and Links, Matthew G. and Just, J{\'{e}}r{\'{e}}my and Clarke, Carling and Bender, Tricia and Huebert, Terry and Mason, Annaliese S. and {Chris Pires}, J. and Barker, Guy and Moore, Jonathan and Walley, Peter G. and Manoli, Sahana and Batley, Jacqueline and Edwards, David and Nelson, Matthew N. and Wang, Xiyin and Paterson, Andrew H. and King, Graham and Bancroft, Ian and Chalhoub, Boulos and Sharpe, Andrew G.},
    doi = {10.1186/gb-2014-15-6-r77},
    issn = {1474760X},
    journal = {Genome Biology},
    month = {jun},
    number = {6},
    publisher = {BioMed Central Ltd.},
    title = {{Transcriptome and methylome profiling reveals relics of genome dominance in the mesopolyploid Brassica oleracea}},
    volume = {15},
    year = {2014}
}

@article{Li:2013,
    abstract = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date. Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa. Contact: hengli@broadinstitute.org},
    archivePrefix = {arXiv},
    arxivId = {1303.3997},
    author = {Li, Heng},
    eprint = {1303.3997},
    month = {mar},
    title = {{Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM}},
    url = {http://arxiv.org/abs/1303.3997},
    year = {2013}
}

@article{McKenna:2010,
    abstract = {Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS--the 1000 Genome pilot alone includes nearly five terabases--make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.},
    author = {McKenna, Aaron and Hanna, Matthew and Banks, Eric and Sivachenko, Andrey and Cibulskis, Kristian and Kernytsky, Andrew and Garimella, Kiran and Altshuler, David and Gabriel, Stacey and Daly, Mark and DePristo, Mark A.},
    doi = {10.1101/gr.107524.110},
    issn = {10889051},
    journal = {Genome Research},
    month = {sep},
    number = {9},
    pages = {1297--1303},
    title = {{The genome analysis toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data}},
    volume = {20},
    year = {2010}
}

@article{Depristo:2011,
    abstract = {Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. We here discuss the application of these tools, instantiated in the Genome Analysis Toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼4×) 1000 Genomes Project datasets.},
    author = {Depristo, Mark A. and Banks, Eric and Poplin, Ryan and Garimella, Kiran V. and Maguire, Jared R. and Hartl, Christopher and Philippakis, Anthony A. and {Del Angel}, Guillermo and Rivas, Manuel A. and Hanna, Matt and McKenna, Aaron and Fennell, Tim J. and Kernytsky, Andrew M. and Sivachenko, Andrey Y. and Cibulskis, Kristian and Gabriel, Stacey B. and Altshuler, David and Daly, Mark J.},
    doi = {10.1038/ng.806},
    issn = {10614036},
    journal = {Nature Genetics},
    month = {may},
    number = {5},
    pages = {491--501},
    title = {{A framework for variation discovery and genotyping using next-generation DNA sequencing data}},
    volume = {43},
    year = {2011}
}

@article{Li:2009,
    abstract = {SUMMARY The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY http://samtools.sourceforge.net.},
    author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard},
    doi = {10.1093/bioinformatics/btp352},
    issn = {13674803},
    journal = {Bioinformatics},
    month = {aug},
    number = {16},
    pages = {2078--2079},
    title = {{The Sequence Alignment/Map format and SAMtools}},
    volume = {25},
    year = {2009}
}

@article{Takagi:2013,
    abstract = {The majority of agronomically important crop traits are quantitative, meaning that they are controlled by multiple genes each with a small effect (quantitative trait loci, QTLs). Mapping and isolation of QTLs is important for efficient crop breeding by marker-assisted selection (MAS) and for a better understanding of the molecular mechanisms underlying the traits. However, since it requires the development and selection of DNA markers for linkage analysis, QTL analysis has been time-consuming and labor-intensive. Here we report the rapid identification of plant QTLs by whole-genome resequencing of DNAs from two populations each composed of 20-50 individuals showing extreme opposite trait values for a given phenotype in a segregating progeny. We propose to name this approach QTL-seq as applied to plant species. We applied QTL-seq to rice recombinant inbred lines and F2 populations and successfully identified QTLs for important agronomic traits, such as partial resistance to the fungal rice blast disease and seedling vigor. Simulation study showed that QTL-seq is able to detect QTLs over wide ranges of experimental variables, and the method can be generally applied in population genomics studies to rapidly identify genomic regions that underwent artificial or natural selective sweeps.},
    author = {Takagi, Hiroki and Abe, Akira and Yoshida, Kentaro and Kosugi, Shunichi and Natsume, Satoshi and Mitsuoka, Chikako and Uemura, Aiko and Utsushi, Hiroe and Tamiru, Muluneh and Takuno, Shohei and Innan, Hideki and Cano, Liliana M. and Kamoun, Sophien and Terauchi, Ryohei},
    doi = {10.1111/tpj.12105},
    issn = {09607412},
    journal = {Plant Journal},
    keywords = {breeding,next generation sequencer,quantitative trait loci,selective sweep,technical advance,whole genome sequencing},
    month = {apr},
    number = {1},
    pages = {174--183},
    title = {{QTL-seq: Rapid mapping of quantitative trait loci in rice by whole genome resequencing of DNA from two bulked populations}},
    volume = {74},
    year = {2013}
}

@article{Magwene:2011,
    abstract = {We describe a statistical framework for QTL mapping using bulk segregant analysis (BSA) based on high throughput, short-read sequencing. Our proposed approach is based on a smoothed version of the standard statistic, and takes into account variation in allele frequency estimates due to sampling of segregants to form bulks as well as variation introduced during the sequencing of bulks. Using simulation, we explore the impact of key experimental variables such as bulk size and sequencing coverage on the ability to detect QTLs. Counterintuitively, we find that relatively large bulks maximize the power to detect QTLs even though this implies weaker selection and less extreme allele frequency differences. Our simulation studies suggest that with large bulks and sufficient sequencing depth, the methods we propose can be used to detect even weak effect QTLs and we demonstrate the utility of this framework by application to a BSA experiment in the budding yeast Saccharomyces cerevisiae. Quantitative or complex phenotypes are traits that are under the control of multiple genes and environmental factors. Identifying the parts of the genome that contribute to variation in complex traits (Quantitative Trait Loci or QTLs), and ultimately the genes and alleles that are mechanistically responsible for trait variation, is a primary challenge in animal and plant breeding, population studies of human health and disease, and evolutionary genetics. In this study we describe an analytical framework that allows investigators to marry a QTL mapping approach called bulk segregant analysis (BSA) with high-throughput genome sequencing methodologies in order to map traits quickly, efficiently, and in a relatively inexpensive manner. This framework provides a statistical basis for analyzing BSA experiments that use next-generation sequencing and will help to accelerate the identification of QTLs in both model and non-model organisms.},
    author = {Magwene, Paul M. and Willis, John H. and Kelly, John K.},
    doi = {10.1371/journal.pcbi.1002255},
    issn = {1553734X},
    journal = {PLoS Computational Biology},
    month = {nov},
    number = {11},
    title = {{The statistics of bulk segregant analysis using next generation sequencing}},
    volume = {7},
    year = {2011}
}

@article{Mansfeld:2018,
    abstract = {Next Generation Sequencing Bulk Segregant Analysis (NGS-BSA) is efficient in detecting quantitative trait loci (QTL). Despite the popularity of NGS-BSA and the R statistical platform, no R packages are currently available for NGS-BSA. We present QTLseqr, an R package for NGS-BSA that identifies QTL using two statistical approaches: QTL-seq and G'. These approaches use a simulation method and a tricube smoothed G statistic, respectively, to identify and assess statistical significance of QTL. QTLseqr, can import and filter SNP data, calculate SNP distributions, relative allele frequencies, G' values, and log10(p-values), enabling identification and plotting of QTL. The source code is available at https://github.com/bmansfeld/QTLseqr},
    author = {Mansfeld, Ben N. and Grumet, Rebecca},
    doi = {10.3835/plantgenome2018.01.0006},
    issn = {19403372},
    journal = {Plant Genome},
    number = {2},
    pages = {1--5},
    title = {{QTLseqr: An R package for bulk segregant analysis with next-generation sequencing}},
    volume = {11},
    year = {2018}
}

@article{Schneider:2009,
    abstract = {The UniProt knowledgebase, UniProtKB, is the main product of the UniProt consortium. It consists of two sections, UniProtKB/Swiss-Prot, the manually curated section, and UniProtKB/TrEMBL, the computer translation of the EMBL/GenBank/DDBJ nucleotide sequence database. Taken together, these two sections cover all the proteins characterized or inferred from all publicly available nucleotide sequences. The Plant Proteome Annotation Program (PPAP) of UniProtKB/Swiss-Prot focuses on the manual annotation of plant-specific proteins and protein families. Our major effort is currently directed towards the two model plants Arabidopsis thaliana and Oryza sativa. In UniProtKB/Swiss-Prot, redundancy is minimized by merging all data from different sources in a single entry. The proposed protein sequence is frequently modified after comparison with ESTs, full length transcripts or homologous proteins from other species. The information present in manually curated entries allows the reconstruction of all described isoforms. The annotation also includes proteomics data such as PTM and protein identification MS experimental results. UniProtKB and the other products of the UniProt consortium are accessible online at www.uniprot.org. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
    author = {Schneider, Michel and Lane, Lydie and Boutet, Emmanuel and Lieberherr, Damien and Tognolli, Michael and Bougueleret, Lydie and Bairoch, Amos},
    doi = {10.1016/j.jprot.2008.11.010},
    issn = {18743919},
    journal = {Journal of Proteomics},
    keywords = {Database,Manual annotation,PTM,Plant,Proteomics,UniProt},
    month = {apr},
    number = {3},
    pages = {567--573},
    title = {{The UniProtKB/Swiss-Prot knowledgebase and its Plant Proteome Annotation Program}},
    volume = {72},
    year = {2009}
}

@article{Smedley:2009,
    abstract = {Biologists need to perform complex queries, often across a variety of databases. Typically, each data resource provides an advanced query interface, each of which must be learnt by the biologist before they can begin to query them. Frequently, more than one data source is required and for high-throughput analysis, cutting and pasting results between websites is certainly very time consuming. Therefore, many groups rely on local bioinformatics support to process queries by accessing the resource's programmatic interfaces if they exist. This is not an efficient solution in terms of cost and time. Instead, it would be better if the biologist only had to learn one generic interface. BioMart provides such a solution.},
    author = {Smedley, Damian and Haider, Syed and Ballester, Benoit and Holland, Richard and London, Darin and Thorisson, Gudmundur and Kasprzyk, Arek},
    doi = {10.1186/1471-2164-10-22},
    issn = {1471-2164},
    journal = {BMC Genomics},
    month = {jan},
    number = {1},
    pages = {22},
    title = {{BioMart – biological queries made easy}},
    url = {http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-10-22},
    volume = {10},
    year = {2009}
}

@misc{Ashburner:2000,
    abstract = {Genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. Knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. The goal of the Gene Ontology Consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. To this end, three independent ontologies accessible on the World-Wide Web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component.},
    author = {Ashburner, Michael and Ball, Catherine A. and Blake, Judith A. and Botstein, David and Butler, Heather and Cherry, J. Michael and Davis, Allan P. and Dolinski, Kara and Dwight, Selina S. and Eppig, Janan T. and Harris, Midori A. and Hill, David P. and Issel-Tarver, Laurie and Kasarskis, Andrew and Lewis, Suzanna and Matese, John C. and Richardson, Joel E. and Ringwald, Martin and Rubin, Gerald M. and Sherlock, Gavin},
    booktitle = {Nature Genetics},
    doi = {10.1038/75556},
    issn = {10614036},
    month = {may},
    number = {1},
    pages = {25--29},
    title = {{Gene ontology: Tool for the unification of biology}},
    volume = {25},
    year = {2000}
}

@article{Du:2010,
    abstract = {Gene Ontology (GO), the de facto standard in gene functionality description, is used widely in functional annotation and enrichment analysis. Here, we introduce agriGO, an integrated web-based GO analysis toolkit for the agricultural community, using the advantages of our previous GO enrichment tool (EasyGO), to meet analysis demands from new technologies and research objectives. EasyGO is valuable for its proficiency, and has proved useful in uncovering biological knowledge in massive data sets from high-throughput experiments. For agriGO, the system architecture and website interface were redesigned to improve performance and accessibility. The supported organisms and gene identifiers were substantially expanded (including 38 agricultural species composed of 274 data types). The requirement on user input is more flexible, in that user-defined reference and annotation are accepted. Moreover, a new analysis approach using Gene Set Enrichment Analysis strategy and customizable features is provided. Four tools, SEA (Singular enrichment analysis), PAGE (Parametric Analysis of Gene set Enrichment), BLAST4ID (Transfer IDs by BLAST) and SEACOMPARE (Cross comparison of SEA), are integrated as a toolkit to meet different demands. We also provide a cross-comparison service so that different data sets can be compared and explored in a visualized way. Lastly, agriGO functions as a GO data repository with search and download functions; agriGO is publicly accessible at http://bioinfo.cau.edu.cn/agriGO/. {\textcopyright} The Author(s) 2010. Published by Oxford University Press.},
    author = {Du, Zhou and Zhou, Xin and Ling, Yi and Zhang, Zhenhai and Su, Zhen},
    doi = {10.1093/nar/gkq310},
    issn = {03051048},
    journal = {Nucleic Acids Research},
    month = {apr},
    number = {SUPPL. 2},
    title = {{agriGO: A GO analysis toolkit for the agricultural community}},
    volume = {38},
    year = {2010}
}

@article{Huang:2009,
    abstract = {Functional analysis of large gene lists, derived in most cases from emerging high-throughput genomic, proteomic and bioinformatics scanning approaches, is still a challenging and daunting task. The gene-annotation enrichment analysis is a promising high-throughput strategy that increases the likelihood for investigators to identify biological processes most pertinent to their study. Approximately 68 bioinformatics enrichment tools that are currently available in the community are collected in this survey. Tools are uniquely categorized into three major classes, according to their underlying enrichment algorithms. The comprehensive collections, unique tool classifications and associated questions/issues will provide a more comprehensive and up-to-date view regarding the advantages, pitfalls and recent trends in a simpler tool-class level rather than by a tool-by-tool approach. Thus, the survey will help tool designers/developers and experienced end users understand the underlying algorithms and pertinent details of particular tool categories/tools, enabling them to make the best choices for their particular research interests.},
    author = {Huang, Da Wei and Sherman, Brad T. and Lempicki, Richard A.},
    doi = {10.1093/nar/gkn923},
    issn = {1362-4962},
    journal = {Nucleic Acids Research},
    month = {jan},
    number = {1},
    pages = {1--13},
    title = {{Bioinformatics enrichment tools: paths toward the comprehensive functional analysis of large gene lists}},
    url = {https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkn923},
    volume = {37},
    year = {2009}
}

@article{Boyle:2004,
    abstract = {SUMMARY: GO::TermFinder comprises a set of object-oriented Perl modules for accessing Gene Ontology (GO) information and evaluating and visualizing the collective annotation of a list of genes to GO terms. It can be used to draw conclusions from microarray and other biological data, calculating the statistical significance of each annotation. GO::TermFinder can be used on any system on which Perl can be run, either as a command line application, in single or batch mode, or as a web-based CGI script. AVAILABILITY: The full source code and documentation for GO::TermFinder are freely available from http://search.cpan.org/dist/GO-TermFinder/.},
    author = {Boyle, Elizabeth I. and Weng, Shuai and Gollub, Jeremy and Jin, Heng and Botstein, David and Cherry, J. Michael and Sherlock, Gavin},
    doi = {10.1093/bioinformatics/bth456},
    issn = {13674803},
    journal = {Bioinformatics},
    month = {dec},
    number = {18},
    pages = {3710--3715},
    title = {{GO::TermFinder - Open source software for accessing Gene Ontology information and finding significantly enriched Gene Ontology terms associated with a list of genes}},
    volume = {20},
    year = {2004}
}

@article{Gotz:2011,
    abstract = {Functional genomics research has expanded enormously in the last decade thanks to the cost reduction in high-throughput technologies and the development of computational tools that generate, standardize and share information on gene and protein function such as the Gene Ontology (GO). Nevertheless, many biologists, especially working with non-model organisms, still suffer from non-existing or low-coverage functional annotation, or simply struggle retrieving, summarizing and querying these data.},
    author = {G{\"{o}}tz, Stefan and Arnold, Roland and Sebasti{\'{a}}n-Le{\'{o}}n, Patricia and Mart{\'{i}}n-Rodr{\'{i}}guez, Samuel and Tischler, Patrick and Jehl, Marc Andr{\'{e}} and Dopazo, Joaqu{\'{i}}n and Rattei, Thomas and Conesa, Ana},
    doi = {10.1093/bioinformatics/btr059},
    issn = {13674803},
    journal = {Bioinformatics},
    month = {apr},
    number = {7},
    pages = {919--924},
    pmid = {21335611},
    title = {{B2G-FAR, a species-centered GO annotation repository}},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/21335611 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3065692},
    volume = {27},
    year = {2011}
}

@article{Conesa:2008,
    abstract = {Functional annotation of novel sequence data is a primary requirement for the utilization of functional genomics approaches in plant research. In this paper, we describe the Blast2GO suite as a comprehensive bioinformatics tool for functional annotation of sequences and data mining on the resulting annotations, primarily based on the gene ontology (GO) vocabulary. Blast2GO optimizes function transfer from homologous sequences through an elaborate algorithm that considers similarity, the extension of the homology, the database of choice, the GO hierarchy, and the quality of the original annotations. The tool includes numerous functions for the visualization, management, and statistical analysis of annotation results, including gene set enrichment analysis. The application supports InterPro, enzyme codes, KEGG pathways, GO direct acyclic graphs (DAGs), and GOSlim. Blast2GO is a suitable tool for plant genomics research because of its versatility, easy installation, and friendly use.},
    author = {Conesa, Ana and G{\"{o}}tz, Stefan},
    doi = {10.1155/2008/619832},
    file = {::},
    issn = {16875370},
    journal = {International Journal of Plant Genomics},
    pages = {1--12},
    pmid = {18483572},
    title = {{Blast2GO: A comprehensive suite for functional analysis in plant genomics}},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/18483572 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2375974 https://www.hindawi.com/archive/2008/619832/},
    volume = {2008},
    year = {2008}
}

@article{Benjamini:2001,
    abstract = {Benjamini and Hochberg suggest that the false discovery rate may be the appropriate error rate to control in many applied multiple testing prob-lems. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of prac-tical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate t. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. For all other forms of dependency, a simple conservative modification of the proce-dure controls the false discovery rate. Thus the range of problems for which a procedure with proven FDR control can be offered is greatly increased.},
    author = {Benjamini, Yoav and Yekutieli, Daniel},
    doi = {10.1214/aos/1013699998},
    issn = {00905364},
    journal = {Annals of Statistics},
    keywords = {Discrete test statistics,FDR,Hochberg's procedure,MTP2 densities,Multiple comparisons procedures,Multiple endpoints many-to-one comparisons,Positive regression dependency,Simes' equality,Unidimensional latent variables},
    month = {aug},
    number = {4},
    pages = {1165--1188},
    title = {{The control of the false discovery rate in multiple testing under dependency}},
    volume = {29},
    year = {2001}
}

@article{Reimand:2016,
    abstract = {Functional enrichment analysis is a key step in interpreting gene lists discovered in diverse high-throughput experiments. g:Profiler studies flat and ranked gene lists and finds statistically significant Gene Ontology terms, pathways and other gene function related terms. Translation of hundreds of gene identifiers is another core feature of g:Profiler. Since its first publication in 2007, our web server has become a popular tool of choice among basic and translational researchers. Timeliness is a major advantage of g:Profiler as genome and pathway information is synchronized with the Ensembl database in quarterly updates. g:Profiler supports 213 species including mammals and other vertebrates, plants, insects and fungi. The 2016 update of g:Profiler introduces several novel features. We have added further functional datasets to interpret gene lists, including transcription factor binding site predictions, Mendelian disease annotations, information about protein expression and complexes and gene mappings of human genetic polymorphisms. Besides the interactive web interface, g:Profiler can be accessed in computational pipelines using our R package, Python interface and BioJS component. g:Profiler is freely available at http://biit.cs.ut.ee/gprofiler/.},
    author = {Reimand, J{\"{u}}ri and Arak, Tambet and Adler, Priit and Kolberg, Liis and Reisberg, Sulev and Peterson, Hedi and Vilo, Jaak},
    doi = {10.1093/nar/gkw199},
    file = {::},
    issn = {0305-1048},
    journal = {Nucleic Acids Research},
    month = {jul},
    number = {W1},
    pages = {W83--W89},
    title = {{g:Profiler—a web server for functional interpretation of gene lists (2016 update)}},
    url = {https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkw199},
    volume = {44},
    year = {2016}
}





